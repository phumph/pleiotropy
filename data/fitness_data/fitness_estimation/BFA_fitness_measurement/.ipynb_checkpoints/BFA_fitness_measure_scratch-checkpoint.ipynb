{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from fitness_assay_debug import inferFitness, inverseVarAve\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from matplotlib.collections import LineCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing BFA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfa2 = pd.read_csv('../Final_Count_Pipeline/BFA_data/Combined_Counts/dBFA2_counts.csv')\n",
    "hbfa1 = pd.read_csv('../Final_Count_Pipeline/BFA_data/Combined_Counts/hBFA1_counts.csv')\n",
    "hbfa2 = pd.read_csv('../Final_Count_Pipeline/BFA_data/Combined_Counts/hBFA2_counts.csv')\n",
    "nd = {'dBFA2': dbfa2, 'hBFA1': hbfa1, 'hBFA2': hbfa2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling putative environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_file = '../env_bc_scratch/Environment_BC_calls_Feb_2018_simple.csv'\n",
    "ed = {i[0]: i[1] for i in pd.read_csv(env_file).as_matrix(['Environment.BC', 'Putative.Environment'])}\n",
    "for n in nd:\n",
    "    td = nd[n]\n",
    "    td['Putative.Environment'] = td.apply(lambda row: ed.setdefault(row['Environment.BC'], 'unknown'), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For dbfa2, I will use the subpool info for the neutral barcodes, which is not in this combined file, but is in the first harvard lane. 'Ancestor_YPD_2N_R1_1' is at about 4 times the frequency of 'Ancestor_YPD_2N_R1_2' and there are ~180 bcs in each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_w_pools = pd.read_csv('../Final_Count_Pipeline/BFA_data/dBFA2_Harvard_1/dBFA2_Harvard_1_bc_counts_clustered.csv')\n",
    "d_w_pools['Full.BC'] = d_w_pools['Diverse.BC'] + d_w_pools['Environment.BC']\n",
    "anc_ypd_1 = d_w_pools.loc[d_w_pools['Ancestor_YPD_2N_R1_1']>5]['Full.BC']\n",
    "anc_ypd_2 = d_w_pools.loc[d_w_pools['Ancestor_YPD_2N_R1_2']>5]['Full.BC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hBFA1 302\n",
      "hBFA2 277\n",
      "dBFA2 177\n"
     ]
    }
   ],
   "source": [
    "putative_neuts = dict()\n",
    "putative_neuts['hBFA1'] = list(hbfa1.loc[hbfa1['Putative.Environment'] == 'YPD_alpha']['Full.BC'])\n",
    "putative_neuts['hBFA2'] = list(hbfa2.loc[hbfa2['Putative.Environment'] == 'CLM_2N']['Full.BC'])\n",
    "putative_neuts['dBFA2'] = list(dbfa2.loc[dbfa2['Full.BC'].isin(anc_ypd_1)]['Full.BC'])\n",
    "\n",
    "for n in putative_neuts:\n",
    "    print(n, len(putative_neuts[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading timepoint exclusion info from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example defaultdict(<class 'list'>, {'R2': ['16']})\n"
     ]
    }
   ],
   "source": [
    "tp_exclusion = pd.read_csv('bfa_timepoint_exclusion_list.csv')\n",
    "tp_ex = defaultdict(lambda: defaultdict(lambda: defaultdict(list))) # dict like tp_ex[bfa_name][env_name][replicate] = list of excluded tps\n",
    "for row in tp_exclusion.as_matrix(['ASSAY', 'ENV', 'REP', 'TIME']):\n",
    "    tp_ex[row[0]][row[1]][row[2]] = row[3].split(';')\n",
    "print('Example', tp_ex['hBFA1']['FLC4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dBFA2 YPD R1 included tps: [1, 2, 3, 4, 5]\n",
      "dBFA2 YPD R2 included tps: [1, 2, 3, 4, 5]\n",
      "dBFA2 YPD R3 included tps: [1, 2, 3, 4, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/fs2k01/srv/export/desai_lab/share_root/users/mjohnson/PLT/BFA_fitness_measurement/fitness_assay_debug.py:206: RuntimeWarning: divide by zero encountered in power\n",
      "  zScores = zScores*np.power(expectedReads,-0.5)\n",
      "/net/fs2k01/srv/export/desai_lab/share_root/users/mjohnson/PLT/BFA_fitness_measurement/fitness_assay_debug.py:206: RuntimeWarning: invalid value encountered in multiply\n",
      "  zScores = zScores*np.power(expectedReads,-0.5)\n",
      "/net/fs2k01/srv/export/desai_lab/share_root/users/mjohnson/PLT/BFA_fitness_measurement/fitness_assay_debug.py:366: RuntimeWarning: divide by zero encountered in log\n",
      "  allTimeFitness = np.log(allReads[repName][:,1:]/totReads[1:])-np.log(allReads[repName][:,0:-1]/totReads[0:-1])\n",
      "/net/fs2k01/srv/export/desai_lab/share_root/users/mjohnson/PLT/BFA_fitness_measurement/fitness_assay_debug.py:366: RuntimeWarning: invalid value encountered in subtract\n",
      "  allTimeFitness = np.log(allReads[repName][:,1:]/totReads[1:])-np.log(allReads[repName][:,0:-1]/totReads[0:-1])\n",
      "/net/fs2k01/srv/export/desai_lab/share_root/users/mjohnson/PLT/BFA_fitness_measurement/fitness_assay_debug.py:371: RuntimeWarning: divide by zero encountered in power\n",
      "  allTimeErrors = np.sqrt(np.power(allReads[repName][:,1:]/kappas,-1)\n",
      "/net/fs2k01/srv/export/desai_lab/share_root/users/mjohnson/PLT/BFA_fitness_measurement/fitness_assay_debug.py:403: RuntimeWarning: invalid value encountered in multiply\n",
      "  weightedMeans = np.sum(meanVals*np.power(standardDevs,-2),axis=1)/np.sum(np.power(standardDevs,-2),axis=1)\n",
      "/net/fs2k01/srv/export/desai_lab/share_root/users/mjohnson/PLT/BFA_fitness_measurement/fitness_assay_debug.py:404: RuntimeWarning: divide by zero encountered in power\n",
      "  weightedStandardDevs = np.power(np.sum(np.power(standardDevs,-2),axis=1),-0.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dBFA2 37C_Stan R1 included tps: [1, 2]\n",
      "dBFA2 37C_Stan R2 included tps: [1, 2, 3, 4]\n",
      "dBFA2 37C_Stan R3 included tps: [1, 2, 3, 4]\n",
      "dBFA2 FLC4 R1 not enough tps\n",
      "dBFA2 FLC4 R2 included tps: [1, 2]\n",
      "dBFA2 FLC4 R3 included tps: [1, 2]\n",
      "dBFA2 SC R1 included tps: [1, 3, 4, 5]\n",
      "dBFA2 SC R2 included tps: [1, 2, 3, 4]\n",
      "dBFA2 SC R3 included tps: [1, 2, 3, 4, 5]\n",
      "dBFA2 CLM R1 included tps: [1, 2]\n",
      "dBFA2 CLM R2 included tps: [1, 2]\n",
      "dBFA2 CLM R3 included tps: [1, 2]\n",
      "dBFA2 21C R1 included tps: [1, 2, 3, 4]\n",
      "dBFA2 21C R2 included tps: [1, 4, 5]\n",
      "dBFA2 21C R3 included tps: [1, 2, 3, 5]\n",
      "dBFA2 pH7_3 R1 included tps: [1, 2, 3, 4, 5]\n",
      "dBFA2 pH7_3 R2 included tps: [1, 2, 3, 4, 5]\n",
      "dBFA2 pH7_3 R3 included tps: [1, 2, 3, 4, 5]\n",
      "dBFA2 pH3_8 R1 included tps: [2, 3, 5]\n",
      "dBFA2 pH3_8 R2 included tps: [2, 4, 5]\n",
      "dBFA2 pH3_8 R3 included tps: [1, 2, 3, 5]\n",
      "dBFA2 GlyEtOH R1 included tps: [1, 2, 3, 4, 5]\n",
      "dBFA2 GlyEtOH R2 included tps: [1, 2, 3]\n",
      "dBFA2 GlyEtOH R3 included tps: [1, 2]\n",
      "dBFA2 48Hr R1 not enough tps\n",
      "dBFA2 48Hr R3 not enough tps\n",
      "dBFA2 02M_NaCl R1 included tps: [1, 2, 4, 5]\n",
      "dBFA2 02M_NaCl R2 included tps: [1, 2, 3, 5]\n",
      "dBFA2 02M_NaCl R3 included tps: [1, 2, 3, 4, 5]\n",
      "dBFA2 37C R1 included tps: [1, 3, 4, 5]\n",
      "dBFA2 37C R2 included tps: [1, 2, 3, 4, 5]\n",
      "dBFA2 37C R3 included tps: [1, 2, 3, 5]\n",
      "hBFA1 YPD R1 included tps: [1, 2, 3, 5]\n",
      "hBFA1 YPD R2 included tps: [1, 2, 3, 5]\n",
      "hBFA1 FLC4 R2 included tps: [1, 3, 5]\n",
      "hBFA1 SC R1 included tps: [1, 2, 3, 5]\n",
      "hBFA1 SC R2 included tps: [1, 2, 3, 5]\n",
      "hBFA1 21C R1 included tps: [1, 2, 3, 5]\n",
      "hBFA1 21C R2 included tps: [1, 2, 3, 5]\n",
      "hBFA1 pH7_3 R1 included tps: [1, 2, 3, 5]\n",
      "hBFA1 pH7_3 R2 included tps: [1, 2, 3, 5]\n",
      "hBFA1 pH3_8 R1 included tps: [1, 2, 3, 5]\n",
      "hBFA1 pH3_8 R2 included tps: [1, 3, 5]\n",
      "hBFA1 GlyEtOH R1 included tps: [1, 2, 5]\n",
      "hBFA1 GlyEtOH R2 included tps: [1, 2, 3, 5]\n",
      "hBFA1 48Hr R1 included tps: [1, 2, 3, 5]\n",
      "hBFA1 48Hr R2 included tps: [1, 2, 3, 5]\n",
      "hBFA1 37C R1 included tps: [1, 2, 3, 5]\n",
      "hBFA1 37C R2 included tps: [1, 2, 5]\n",
      "hBFA2 YPD R1 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 YPD R2 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 FLC4 R1 included tps: [1, 2, 3]\n",
      "hBFA2 FLC4 R2 included tps: [1, 2, 3]\n",
      "hBFA2 FLC4 R3 included tps: [2, 3]\n",
      "hBFA2 SC R1 included tps: [1, 2, 3, 4]\n",
      "hBFA2 SC R2 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 SC R3 included tps: [1, 2, 4, 5]\n",
      "hBFA2 CLM R1 included tps: [1, 2]\n",
      "hBFA2 CLM R2 included tps: [1, 2]\n",
      "hBFA2 CLM R3 included tps: [1, 2]\n",
      "hBFA2 21C R1 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 21C R2 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 21C R3 included tps: [1, 3, 4, 5]\n",
      "hBFA2 pH7_3 R1 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 pH7_3 R2 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 pH3_8 R1 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 pH3_8 R2 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 08M_NaCl R1 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 08M_NaCl R2 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 08M_NaCl R3 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 GlyEtOH R1 included tps: [1, 2, 3, 4]\n",
      "hBFA2 GlyEtOH R2 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 GlyEtOH R3 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 48Hr R1 included tps: [2, 3, 5]\n",
      "hBFA2 48Hr R2 included tps: [2, 4, 5]\n",
      "hBFA2 02M_NaCl R1 included tps: [2, 3, 4, 5]\n",
      "hBFA2 02M_NaCl R2 included tps: [2, 3, 4, 5]\n",
      "hBFA2 02M_NaCl R3 included tps: [2, 3, 4, 5]\n",
      "hBFA2 37C R1 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 37C R2 included tps: [1, 2, 3, 4, 5]\n",
      "hBFA2 37C R3 included tps: [1, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "fit_data = defaultdict(dict)\n",
    "c_times = [1, 2, 3, 4, 5]\n",
    "for bfa_name in nd:\n",
    "    td = nd[bfa_name]\n",
    "    bcs = list(td['Full.BC'])\n",
    "    envs = set([i.split('-')[1] for i in td.columns if 'Time' in i and i.split('-')[1] not in ['Pre', 'T0_Pool']])\n",
    "    for env in envs:\n",
    "        read_dat = dict()\n",
    "        reps = sorted(set([i.split('-')[2] for i in td.columns if 'Time' in i and env in i]))\n",
    "        for rep in reps:\n",
    "            if not 'EXCLUDE ALL' in tp_ex[bfa_name][env][rep]:\n",
    "                excluded_tps = tp_ex[bfa_name][env][rep]\n",
    "                tps = [bfa_name + '-' + env + '-' + rep + '-Time' + str(i*8) for i in c_times]\n",
    "                # to exclude timepoints I will just zero out the counts so they will be caught by the low coverage thresh\n",
    "                for tp in tps:\n",
    "                    if tp[tp.index('Time')+4:] in excluded_tps:\n",
    "                        td[tp] = np.zeros(len(td))\n",
    "                tmp_read_dat = np.nan_to_num(td.as_matrix([bfa_name + '-' + env + '-' + rep + '-Time' + str(i*8) for i in c_times]))\n",
    "                included_tps = [i for i in c_times if np.sum(tmp_read_dat, axis=0)[i-1] > 1e5]\n",
    "                if len(included_tps) < 2:\n",
    "                    print(bfa_name, env, rep, 'not enough tps')\n",
    "                else:\n",
    "                    print(bfa_name, env, rep, 'included tps:', included_tps)\n",
    "                    read_dat[rep] = tmp_read_dat\n",
    "        if len(read_dat) > 0:\n",
    "            fit_data[bfa_name][env] = inferFitness(bcs, c_times, read_dat, outputFolder = 'test_Atish_out/', \n",
    "                                              experimentName = bfa_name+'-'+env+'-', lowCoverageThresh=1e5, \n",
    "                                              neutralBarcodes=putative_neuts[bfa_name])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each barcode, I will take both the inverse variance weighted average and an unweighted average of s measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/fs2k01/srv/export/desai_lab/share_root/users/mjohnson/PLT/BFA_fitness_measurement/fitness_assay_debug.py:404: RuntimeWarning: divide by zero encountered in power\n",
      "  weightedStandardDevs = np.power(np.sum(np.power(standardDevs,-2),axis=1),-0.5)\n"
     ]
    }
   ],
   "source": [
    "fdat_short = dict()\n",
    "for bfa_name in nd:\n",
    "    td = nd[bfa_name]\n",
    "    td.sort_values(by='Full.BC', inplace=True)\n",
    "    td['putative_neutral'] = td['Full.BC'].isin(putative_neuts[bfa_name])\n",
    "    for env in fit_data[bfa_name]:\n",
    "        tmp = fit_data[bfa_name][env][0]\n",
    "        reps = [i for i in tmp.keys() if 'R' in i]\n",
    "        s_aves = np.array([tmp[r]['aveFitness'] for r in reps]).T\n",
    "        s_errs = np.array([tmp[r]['aveError'] for r in reps]).T\n",
    "        tmp['iva_s'], tmp['iva_s_err'] = inverseVarAve(s_aves, s_errs)\n",
    "        tmp['ave_s'] = np.mean(s_aves, axis=1)\n",
    "        tmp['ave_err'] = np.power(np.mean(np.power(s_errs, 2),axis=1), 0.5)\n",
    "        for r in reps:\n",
    "            td[env + '-' + r + '-aveFitness'] = tmp[r]['aveFitness']\n",
    "            td[env + '-' + r + '-aveError'] = tmp[r]['aveError']\n",
    "        for key in ['iva_s', 'iva_s_err', 'ave_s', 'ave_err']:\n",
    "            td[env + '-' + key] = tmp[key]\n",
    "        td['used_as_neutral_in_' + env] = fit_data[bfa_name][env][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-18f2fdada621>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbfa_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Full.BC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Diverse.BC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Environment.BC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Putative.Environment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'ave'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'iva'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'neutral'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'03_07_18_fitness_estimates/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbfa_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_03_07_18_s.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/milo_simple_conda5/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1522\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1524\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/milo_simple_conda5/lib/python3.6/site-packages/pandas/io/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for bfa_name in nd:\n",
    "    td = nd[bfa_name]\n",
    "    cols = ['Full.BC', 'Diverse.BC', 'Environment.BC', 'Putative.Environment'] + [i for i in td.columns if 'ave' in i or 'iva' in i or 'neutral' in i]\n",
    "    td.to_csv('03_07_18_fitness_estimates/' + bfa_name + '_03_07_18_s.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding frequency information for plotting later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in nd:\n",
    "    td = nd[n]\n",
    "    all_tps = [i for i in td.columns if 'Time' in i and 'logfreq' not in i]\n",
    "    for tp in all_tps:\n",
    "        tmp_sum = sum(td[tp])\n",
    "        td[tp + '.logfreq.plot'] = np.log10(np.clip((td[tp] / tmp_sum), 10**(-6), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting s correlations between replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bfa_name in nd:\n",
    "    for env in fit_data[bfa_name]:\n",
    "        tmp = fit_data[bfa_name][env][0]\n",
    "        reps = [i for i in tmp.keys() if 'R' in i]\n",
    "        if len(reps) > 1:\n",
    "            fig, subps = pl.subplots(len(reps), len(reps), figsize=(5*len(reps), 5*len(reps)), sharex=True, sharey=True)\n",
    "            mn = max([i for i in tmp['ave_s']/8 if i < 10])\n",
    "            mx = min([i for i in tmp['ave_s']/8 if i > -10])\n",
    "            for i in range(len(reps)):\n",
    "                for j in range(len(reps)):\n",
    "                    subps[i][j].plot([mn, mx], [mn, mx], linestyle='dashed', color='k', alpha=0.5)\n",
    "                    if i == j:\n",
    "                        subps[i][j].scatter(tmp[reps[i]]['aveFitness']/8, tmp['ave_s']/8)\n",
    "                        subps[i][j].set_xlabel(reps[i])\n",
    "                        subps[i][j].set_ylabel('replicate average')\n",
    "                    else:\n",
    "                        subps[i][j].scatter(tmp[reps[i]]['aveFitness']/8, tmp[reps[j]]['aveFitness']/8)\n",
    "                        subps[i][j].set_xlabel(reps[i])\n",
    "                        subps[i][j].set_ylabel(reps[j])\n",
    "                    \n",
    "                    \n",
    "            fig.savefig('prelim_graphs/s_correlations/' + bfa_name + '-' + env + '_unweighted_ave.png')\n",
    "            pl.close(\"all\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bfa_name in nd:\n",
    "    for env in fit_data[bfa_name]:\n",
    "        tmp = fit_data[bfa_name][env][0]\n",
    "        reps = [i for i in tmp.keys() if 'R' in i]\n",
    "        if len(reps) > 1:\n",
    "            fig, subps = pl.subplots(len(reps), len(reps), figsize=(5*len(reps), 5*len(reps)), sharex=True, sharey=True)\n",
    "            mn = max([i for i in tmp['iva_s']/8 if i < 10])\n",
    "            mx = min([i for i in tmp['iva_s']/8 if i > -10])\n",
    "            for i in range(len(reps)):\n",
    "                for j in range(len(reps)):\n",
    "                    subps[i][j].plot([mn, mx], [mn, mx], linestyle='dashed', color='k', alpha=0.5)\n",
    "                    if i == j:\n",
    "                        subps[i][j].scatter(tmp[reps[i]]['aveFitness']/8, tmp['iva_s']/8)\n",
    "                        subps[i][j].set_xlabel(reps[i])\n",
    "                        subps[i][j].set_ylabel('replicate average')\n",
    "                    else:\n",
    "                        subps[i][j].scatter(tmp[reps[i]]['aveFitness']/8, tmp[reps[j]]['aveFitness']/8)\n",
    "                        subps[i][j].set_xlabel(reps[i])\n",
    "                        subps[i][j].set_ylabel(reps[j])\n",
    "                    \n",
    "                    \n",
    "            fig.savefig('prelim_graphs/s_correlations/' + bfa_name + '-' + env + '_iva.png')\n",
    "            pl.close(\"all\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bfa_name = 'dBFA2'    \n",
    "td = nd[bfa_name]\n",
    "fig, subps = pl.subplots(6, 2, figsize=(16, 20))\n",
    "envs = [i for i in fit_data[bfa_name]]\n",
    "c = 0\n",
    "bc_list = sorted(list(nd[bfa_name]['Full.BC']))\n",
    "for subarr in subps:\n",
    "    for sub in subarr:\n",
    "        if c < len(envs):\n",
    "            env = envs[c]\n",
    "            bcs_inferred_neut = [bc_list[i] for i in range(len(bc_list)) if fit_data[bfa_name][env][1][i]]\n",
    "            c += 1\n",
    "            tmp = fit_data[bfa_name][env][0]\n",
    "            use_s = [tmp['iva_s'][i] for i in range(len(bc_list)) if bc_list[i] in list(anc_ypd_1)]\n",
    "            use_s_2 = [tmp['ave_s'][i] for i in range(len(bc_list)) if bc_list[i] in list(anc_ypd_1)]\n",
    "            #use_s_2 = [tmp['iva_s'][i] for i in range(len(bc_list)) if bc_list[i] in list(anc_ypd_2)]\n",
    "            #use_s_2 = [tmp['ave_s'][i] for i in range(len(bc_list)) if bc_list[i] in list(bcs_inferred_neut)]\n",
    "            #sub.hist(np.clip(np.nan_to_num(tmp['ave_s'])/8, -0.05, 0.05), bins=50, color='k', alpha=0.5, normed=True)\n",
    "            sub.hist(np.clip(np.nan_to_num(use_s)/8, -0.05, 0.05), bins=50, color='r', alpha=0.5, normed=True)\n",
    "            sub.hist(np.clip(np.nan_to_num(use_s_2)/8, -0.05, 0.05), bins=50, color='y', alpha=0.5, normed=True)\n",
    "            sub.set_title(env, y=0.8, x=0.15)\n",
    "fig.savefig('prelim_graphs/neut_s_distribs/dBFA2_neut_s_distrib_.png')\n",
    "\n",
    "for r in ['R1', 'R2', 'R3']:\n",
    "    fig, subps = pl.subplots(6, 2, figsize=(16, 20))\n",
    "    c = 0\n",
    "    for subarr in subps:\n",
    "        for sub in subarr:\n",
    "            if c < len(envs):\n",
    "                env = envs[c]\n",
    "                bcs_inferred_neut = [bc_list[i] for i in range(len(bc_list)) if fit_data[bfa_name][env][1][i]]\n",
    "                c += 1\n",
    "                tmp = fit_data[bfa_name][env][0]\n",
    "                if r in tmp:\n",
    "                    use_s = [tmp[r]['aveFitness'][i] for i in range(len(bc_list)) if bc_list[i] in list(anc_ypd_1)]\n",
    "                    sub.hist(np.clip(np.nan_to_num(use_s)/8, -0.05, 0.05), bins=50, color='r', alpha=0.5, normed=True)\n",
    "                    sub.set_title(env, y=0.8, x=0.15)\n",
    "    fig.savefig('prelim_graphs/neut_s_distribs/by_rep/dBFA2_' + r + '_neut_s_distrib_.png')\n",
    "    pl.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bfa_name in ['hBFA1', 'hBFA2' ]:   \n",
    "    td = nd[bfa_name]\n",
    "    fig, subps = pl.subplots(5, 2, figsize=(16, 20))\n",
    "    envs = [i for i in fit_data[bfa_name]]\n",
    "    c = 0\n",
    "    bc_list = sorted(list(nd[bfa_name]['Full.BC']))\n",
    "    for subarr in subps:\n",
    "        for sub in subarr:\n",
    "            if c < len(envs):\n",
    "                env = envs[c]\n",
    "                c += 1\n",
    "                tmp = fit_data[bfa_name][env][0]\n",
    "                use_s = [tmp['iva_s'][i] for i in range(len(bc_list)) if bc_list[i] in putative_neuts[bfa_name]]\n",
    "                use_s_2 = [tmp['ave_s'][i] for i in range(len(bc_list)) if bc_list[i] in putative_neuts[bfa_name]]\n",
    "                sub.hist(np.clip(np.nan_to_num(use_s)/8, -0.05, 0.05), bins=50, color='r', alpha=0.5, normed=True)\n",
    "                sub.hist(np.clip(np.nan_to_num(use_s_2)/8, -0.05, 0.05), bins=50, color='y', alpha=0.5, normed=True)\n",
    "                sub.set_title(env, y=0.8, x=0.15)\n",
    "    fig.savefig('prelim_graphs/neut_s_distribs/' + bfa_name + '_neut_s_distrib.png')\n",
    "    \n",
    "    reps = ['R1', 'R2', 'R3']\n",
    "    if bfa_name == 'hBFA1':\n",
    "        reps = ['R1', 'R2']\n",
    "    for r in reps:\n",
    "        fig, subps = pl.subplots(5, 2, figsize=(16, 20))\n",
    "        c = 0\n",
    "        for subarr in subps:\n",
    "            for sub in subarr:\n",
    "                if c < len(envs):\n",
    "                    env = envs[c]\n",
    "                    bcs_inferred_neut = [bc_list[i] for i in range(len(bc_list)) if fit_data[bfa_name][env][1][i]]\n",
    "                    c += 1\n",
    "                    tmp = fit_data[bfa_name][env][0]\n",
    "                    if r in tmp:\n",
    "                        use_s = [tmp[r]['aveFitness'][i] for i in range(len(bc_list)) if bc_list[i] in putative_neuts[bfa_name]]\n",
    "                        sub.hist(np.clip(np.nan_to_num(use_s)/8, -0.05, 0.05), bins=50, color='r', alpha=0.5, normed=True)\n",
    "                        sub.set_title(env, y=0.8, x=0.15)\n",
    "        fig.savefig('prelim_graphs/neut_s_distribs/by_rep/' + bfa_name + '_' + r + '_neut_s_distrib_.png')\n",
    "        pl.close(\"all\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bfa_name in nd:   \n",
    "    td = nd[bfa_name]\n",
    "    envs = [i for i in fit_data[bfa_name]]\n",
    "    fig, subps = pl.subplots(len(envs), 3, figsize=(16, 4*len(envs)))\n",
    "    c = 0\n",
    "    bc_list = sorted(list(td['Full.BC']))\n",
    "    for e in range(len(envs)):\n",
    "        bcs_inferred_neut = [bc_list[i] for i in range(len(bc_list)) if fit_data[bfa_name][envs[e]][1][i]]\n",
    "        td_highlight = td.loc[td['Full.BC'].isin(bcs_inferred_neut)]\n",
    "        td_given_neuts = td.loc[td['Full.BC'].isin(putative_neuts[bfa_name])]\n",
    "        for r in range(3):\n",
    "            if not 'EXCLUDE ALL' in tp_ex[bfa_name][envs[e]]['R'+str(r+1)]:\n",
    "                excluded_tps = [bfa_name + '-' + envs[e] + '-R' + str(r+1) + '-Time' + i + '.logfreq.plot' for i in tp_ex[bfa_name][envs[e]]['R'+str(r+1)]]\n",
    "                #print(bfa_name, envs[e], r+1, excluded_tps)\n",
    "                rep = envs[e] + '-R' + str(r+1)\n",
    "                tps = [i for i in td.columns if 'Time' in i and rep in i and '.logfreq' in i and i not in excluded_tps]\n",
    "                if len(tps) != 0:\n",
    "                    times = [int(x[x.index('Time')+4:x.index('.log')]) for x in tps]\n",
    "                    rows = td.as_matrix(tps)\n",
    "                    all_lines = np.zeros((len(rows), len(times), 2), float)\n",
    "                    for j in range(len(rows)):\n",
    "                        all_lines[j, :, 1] = rows[j]\n",
    "                        all_lines[j, :, 0] = times\n",
    "                    lines = LineCollection(all_lines, color='k', alpha=0.1, linewidths=1)\n",
    "                    subps[e][r].add_collection(lines)\n",
    "\n",
    "                    rows = td_given_neuts.as_matrix(tps)\n",
    "                    all_lines = np.zeros((len(rows), len(times), 2), float)\n",
    "                    for j in range(len(rows)):\n",
    "                        all_lines[j, :, 1] = rows[j]\n",
    "                        all_lines[j, :, 0] = times\n",
    "                    lines = LineCollection(all_lines, color='b', alpha=0.25, linewidths=1)\n",
    "                    subps[e][r].add_collection(lines)\n",
    "\n",
    "                    rows = td_highlight.as_matrix(tps)\n",
    "                    all_lines = np.zeros((len(rows), len(times), 2), float)\n",
    "                    for j in range(len(rows)):\n",
    "                        all_lines[j, :, 1] = rows[j]\n",
    "                        all_lines[j, :, 0] = times\n",
    "                    lines = LineCollection(all_lines, color='r', alpha=0.25, linewidths=1)\n",
    "                    subps[e][r].add_collection(lines)\n",
    "                    subps[e][r].plot(times, np.median(rows, axis=0), color='g')\n",
    "                    subps[e][r].set_ylim([-6, 0])\n",
    "                    subps[e][r].set_xlim([8, max(times)])\n",
    "                    subps[e][r].set_title(envs[e])\n",
    "\n",
    "    fig.savefig('prelim_graphs/neut_trajectories/' + bfa_name + '_neutral_inferred.png')\n",
    "    pl.close(\"all\")  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
