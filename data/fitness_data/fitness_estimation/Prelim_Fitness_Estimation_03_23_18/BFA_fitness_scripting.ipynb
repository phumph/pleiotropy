{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hBFA1 has 304 control bcs\n",
      "hBFA2 has 367 control bcs\n",
      "dBFA2 has 177 control bcs\n",
      "Example defaultdict(<class 'list'>, {'R2': ['16']})\n",
      "Min GC #/26 is 4\n",
      "dBFA2 5866 bcs, 5530 meet this cutoff, or 94 %\n",
      "hBFA1 2586 bcs, 2316 meet this cutoff, or 89 %\n",
      "hBFA2 3802 bcs, 3106 meet this cutoff, or 81 %\n",
      "hBFA1 has 288 control bcs\n",
      "hBFA2 has 345 control bcs\n",
      "dBFA2 has 165 control bcs\n",
      "Min GC #/26 is 5\n",
      "dBFA2 5866 bcs, 4314 meet this cutoff, or 73 %\n",
      "hBFA1 2586 bcs, 1847 meet this cutoff, or 71 %\n",
      "hBFA2 3802 bcs, 2534 meet this cutoff, or 66 %\n",
      "hBFA1 has 242 control bcs\n",
      "hBFA2 has 298 control bcs\n",
      "dBFA2 has 91 control bcs\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as pl\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from fitness_assay_returns_more import inferFitness, inverseVarAve\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from milo_tools import reverse_transcribe\n",
    "\n",
    "# including the sequence between the barcodes to get the max AT run of the whole region (which is flanked by CG seqs)\n",
    "middle_seq = 'ATAACTTCGTATAATGTATGCTATACGAAGTTAT'\n",
    "\n",
    "def gc(s):\n",
    "    return len([i for i in s if i in ['G', 'C']])\n",
    "    \n",
    "def sliding_window_min(row, win_size):\n",
    "    s = row['Diverse.BC'] + middle_seq + reverse_transcribe(row['Environment.BC'])\n",
    "    return min([gc(s[i:i+win_size]) for i in range(len(s)-win_size+1)])\n",
    "            \n",
    "def inverseVarAve_w_nan(meanVals,standardDevs):\n",
    "    \"\"\"\n",
    "    inverseVarAve - take weighted average with inverse variances.\n",
    "    :param meanVals: Values to be averaged, N x q. Averaged across second dimension\n",
    "    :param standardDevs: Standard errors of each value, N x q\n",
    "    :return weightedMeans: N x 1 vector of weighted average\n",
    "    :return weightedStandardDevs: N x 1 vector of final standard error\n",
    "    \"\"\"\n",
    "\n",
    "    weightedMeans = np.nansum(meanVals*np.power(standardDevs,-2),axis=1)/np.nansum(np.power(standardDevs,-2),axis=1)\n",
    "    weightedStandardDevs = np.power(np.nansum(np.power(standardDevs,-2),axis=1),-0.5)\n",
    "\n",
    "    return weightedMeans,weightedStandardDevs\n",
    "\n",
    "def measure_fitness(td, putative_neutral_bcs, tp_ex, bfa_name):\n",
    "    fit_data = dict()\n",
    "    c_times = [1, 2, 3, 4, 5]\n",
    "    td.sort_values(by='Full.BC', inplace=True)\n",
    "    bcs = list(td['Full.BC'])\n",
    "    envs = set([i.split('-')[1] for i in td.columns if 'Time' in i and i.split('-')[1] not in ['Pre', 'T0_Pool']])\n",
    "    for env in envs:\n",
    "        read_dat = dict()\n",
    "        reps = sorted(set([i.split('-')[2] for i in td.columns if 'Time' in i and env in i]))\n",
    "        for rep in reps:\n",
    "            if not 'EXCLUDE ALL' in tp_ex[env][rep]:\n",
    "                excluded_tps = tp_ex[env][rep]\n",
    "                tps = [bfa_name + '-' + env + '-' + rep + '-Time' + str(i*8) for i in c_times]\n",
    "                # to exclude timepoints I will just zero out the counts so they will be caught by the low coverage thresh\n",
    "                for tp in tps:\n",
    "                    if tp[tp.index('Time')+4:] in excluded_tps:\n",
    "                        td[tp] = np.zeros(len(td))\n",
    "                tmp_read_dat = np.nan_to_num(td.as_matrix([bfa_name + '-' + env + '-' + rep + '-Time' + str(i*8) for i in c_times]))\n",
    "                included_tps = [i for i in c_times if np.sum(tmp_read_dat, axis=0)[i-1] > 1e5]\n",
    "                if len(included_tps) < 2:\n",
    "                    pass # print(bfa_name, env, rep, 'not enough tps')\n",
    "                else:\n",
    "                    read_dat[rep] = tmp_read_dat\n",
    "                    #print(bfa_name, env, rep, 'included tps:', included_tps)\n",
    "        if len(read_dat) > 0:\n",
    "            fit_data[env], used_neuts = inferFitness(bcs, c_times, read_dat, outputFolder = 'test_Atish_out/', \n",
    "                                              experimentName = bfa_name+'-'+env+'-', lowCoverageThresh=1e5, \n",
    "                                              neutralBarcodes=putative_neutral_bcs)\n",
    "            # averaging across replicates and adding to fit_data\n",
    "            tmp = fit_data[env]\n",
    "            reps = [i for i in tmp.keys() if 'R' in i]\n",
    "            s_aves = np.array([tmp[r]['aveFitness'] for r in reps]).T\n",
    "            s_errs = np.array([tmp[r]['aveError'] for r in reps]).T\n",
    "            td[env + '-iva_s'], td[env + '-iva_s_err'] = inverseVarAve_w_nan(s_aves, s_errs)\n",
    "            td[env + '-ave_s'] = np.nanmean(s_aves, axis=1)\n",
    "            td[env + '-ave_err'] = np.power(np.mean(np.power(s_errs, 2),axis=1), 0.5)\n",
    "            for r in reps:\n",
    "                td[env + '-' + r + '-aveFitness'] = tmp[r]['aveFitness']\n",
    "                td[env + '-' + r + '-aveError'] = tmp[r]['aveError']\n",
    "            td['used_as_neutral_in_' + env] = used_neuts\n",
    "            \n",
    "def plot_s_corr(td, bfa_name, output_base, file_end):\n",
    "    envs = set([i.split('-')[0] for i in td.columns if '-iva_s' in i])\n",
    "    for env in envs:\n",
    "        reps = [i.split('-')[1] for i in td.columns if env+'-R' in i and '-aveFitness' in i]\n",
    "        if len(reps) > 1:\n",
    "            fig, subps = pl.subplots(len(reps), len(reps), figsize=(5*len(reps), 5*len(reps)), sharex=True, sharey=True)\n",
    "            mn = max([i for i in td[env + '-iva_s']/8 if i < 10])\n",
    "            mx = min([i for i in td[env + '-iva_s']/8 if i > -10])\n",
    "            for i in range(len(reps)):\n",
    "                for j in range(len(reps)):\n",
    "                    subps[i][j].plot([mn, mx], [mn, mx], linestyle='dashed', color='k', alpha=0.5)\n",
    "                    if i == j:\n",
    "                        subps[i][j].scatter(td[env + '-' + reps[i] + '-aveFitness']/8, td[env + '-iva_s']/8)\n",
    "                        subps[i][j].set_xlabel(reps[i])\n",
    "                        subps[i][j].set_ylabel('replicate average')\n",
    "                    else:\n",
    "                        subps[i][j].scatter(td[env + '-' + reps[i] + '-aveFitness']/8, td[env + '-' + reps[j] + '-aveFitness']/8)\n",
    "                        subps[i][j].set_xlabel(reps[i])\n",
    "                        subps[i][j].set_ylabel(reps[j])\n",
    "\n",
    "\n",
    "            fig.savefig(output_base + bfa_name + '-' + env + '_iva' + file_end)\n",
    "            pl.close(\"all\") \n",
    "\n",
    "            \n",
    "def column_is_s_related(c):\n",
    "    for s in ['-iva_s', 'iva_s_err', '-ave_s', '-ave_err', '-aveFitness', '-aveError']:\n",
    "        if s in c:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "info_cols = ['Diverse.BC', 'Environment.BC', 'Full.BC', 'Subpool.Environment', 'Which.Subpools']\n",
    "            \n",
    "dbfa2 = pd.read_csv('../Final_Count_Pipeline/BFA_data/Combined_Counts/dBFA2_counts_with_env_info.csv')\n",
    "hbfa1 = pd.read_csv('../Final_Count_Pipeline/BFA_data/Combined_Counts/hBFA1_counts_with_env_info.csv')\n",
    "hbfa2 = pd.read_csv('../Final_Count_Pipeline/BFA_data/Combined_Counts/hBFA2_counts_with_env_info.csv')\n",
    "dats = {'dBFA2': dbfa2, 'hBFA1': hbfa1, 'hBFA2': hbfa2}\n",
    "\n",
    "putative_neuts = dict()\n",
    "putative_neuts['hBFA1'] = list(hbfa1.loc[hbfa1['Subpool.Environment'] == 'YPD_alpha']['Full.BC'])\n",
    "putative_neuts['hBFA2'] = list(hbfa2.loc[hbfa2['Subpool.Environment'] == 'CLM_2N']['Full.BC'])\n",
    "putative_neuts['dBFA2'] = list(dbfa2.loc[dbfa2['Subpool.Environment'] == 'Ancestor_YPD_2N'].loc[dbfa2['Which.Subpools'] == '-R1-1']['Full.BC'])\n",
    "\n",
    "for b in putative_neuts:\n",
    "    print(b, 'has', len(putative_neuts[b]), 'control bcs')\n",
    "    \n",
    "tp_exclusion = pd.read_csv('bfa_timepoint_exclusion_list.csv')\n",
    "tp_ex_by_bfa = defaultdict(lambda: defaultdict(lambda: defaultdict(list))) # dict like tp_ex[bfa_name][env_name][replicate] = list of excluded tps\n",
    "for row in tp_exclusion.as_matrix(['ASSAY', 'ENV', 'REP', 'TIME']):\n",
    "    tp_ex_by_bfa[row[0]][row[1]][row[2]] = row[3].split(';')\n",
    "print('Example', tp_ex_by_bfa['hBFA1']['FLC4'])\n",
    "\n",
    "for b in dats:\n",
    "    measure_fitness(dats[b], putative_neuts[b], tp_ex_by_bfa[b], b)\n",
    "    cols = [i for i in dats[b].columns if column_is_s_related(i)]\n",
    "    dats[b][info_cols + cols].to_csv('03_23_18_fitness_estimates/' + b + '_s_03_23_18_all.csv', index=False)\n",
    "    plot_s_corr(dats[b], b, 's_graphs/s_correlations/', '_all.png')\n",
    "    \n",
    "for gc_cutoff in [4, 5]:\n",
    "    print('Min GC #/26 is', gc_cutoff)\n",
    "    at_reduced = dict()\n",
    "    for b in dats:\n",
    "        td = dats[b]\n",
    "        td['min.lox.GC.w26'] = td.apply(lambda row: sliding_window_min(row, 26), axis=1)\n",
    "        at_reduced[b] = td.loc[td['min.lox.GC.w26'] >= gc_cutoff]\n",
    "        print(b, len(dats[b]), 'bcs,', len(at_reduced[b]), 'meet this cutoff, or', str((100*len(at_reduced[b]))/len(dats[b]))[:2], '%')\n",
    "        \n",
    "    at_reduced_neuts = dict()\n",
    "    at_reduced_neuts['hBFA1'] = list(at_reduced['hBFA1'].loc[at_reduced['hBFA1']['Subpool.Environment'] == 'YPD_alpha']['Full.BC'])\n",
    "    at_reduced_neuts['hBFA2'] = list(at_reduced['hBFA2'].loc[at_reduced['hBFA2']['Subpool.Environment'] == 'CLM_2N']['Full.BC'])\n",
    "    at_reduced_neuts['dBFA2'] = list(at_reduced['dBFA2'].loc[at_reduced['dBFA2']['Subpool.Environment'] == 'Ancestor_YPD_2N'].loc[dbfa2['Which.Subpools'] == '-R1-1']['Full.BC'])\n",
    "\n",
    "    for b in at_reduced_neuts:\n",
    "        print(b, 'has', len(at_reduced_neuts[b]), 'control bcs')\n",
    "    \n",
    "    for b in at_reduced:\n",
    "        measure_fitness(at_reduced[b], at_reduced_neuts[b], tp_ex_by_bfa[b], b)\n",
    "        cols = [i for i in at_reduced[b].columns if column_is_s_related(i)]\n",
    "        at_reduced[b][info_cols + cols].to_csv('03_23_18_fitness_estimates/' + b + '_s_03_23_18_GC_cutoff_' + str(gc_cutoff) + '.csv', index=False)\n",
    "        plot_s_corr(at_reduced[b], b, 's_graphs/s_correlations/', '_GC_cutoff_' + str(gc_cutoff) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
