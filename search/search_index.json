{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Pleiotropy Lineage Tracking (PLT) Project","title":"Pleiotropy Lineage Tracking (PLT) Project"},{"location":"index.html#pleiotropy-lineage-tracking-plt-project","text":"","title":"Pleiotropy Lineage Tracking (PLT) Project"},{"location":"Results/Fitness%20patterns/barcode-level.html","text":"Barcode-level t-SNE","title":"Barcode-level"},{"location":"Results/Fitness%20patterns/barcode-level.html#barcode-level","text":"","title":"Barcode-level"},{"location":"Results/Fitness%20patterns/barcode-level.html#t-sne","text":"","title":"t-SNE"},{"location":"Results/Fitness%20patterns/cluster-level.html","text":"Cluster-level 1N plots Fitness traces by cluster Pleiotropic effects by cluster 2N plots Fitness traces by cluster Pleiotropic effects by cluster Pairwise distances between clusters Pairwise distances between fitness clusters, computed within and between ploidies . Panel columns are source environments, while panel rows are ploidy comparisons (e.g., 1N_1N is haploid versus haploid).","title":"Cluster-level"},{"location":"Results/Fitness%20patterns/cluster-level.html#cluster-level","text":"","title":"Cluster-level"},{"location":"Results/Fitness%20patterns/cluster-level.html#1n-plots","text":"","title":"1N plots"},{"location":"Results/Fitness%20patterns/cluster-level.html#fitness-traces-by-cluster","text":"","title":"Fitness traces by cluster"},{"location":"Results/Fitness%20patterns/cluster-level.html#pleiotropic-effects-by-cluster","text":"","title":"Pleiotropic effects by cluster"},{"location":"Results/Fitness%20patterns/cluster-level.html#2n-plots","text":"","title":"2N plots"},{"location":"Results/Fitness%20patterns/cluster-level.html#fitness-traces-by-cluster_1","text":"","title":"Fitness traces by cluster"},{"location":"Results/Fitness%20patterns/cluster-level.html#pleiotropic-effects-by-cluster_1","text":"","title":"Pleiotropic effects by cluster"},{"location":"Results/Fitness%20patterns/cluster-level.html#pairwise-distances-between-clusters","text":"Pairwise distances between fitness clusters, computed within and between ploidies . Panel columns are source environments, while panel rows are ploidy comparisons (e.g., 1N_1N is haploid versus haploid).","title":"Pairwise distances between clusters"},{"location":"Results/Fitness%20patterns/scatterplots.html","text":"Home v away comparisons Plots below represent the weighted mean fitness in the home environment ( \\(\\pm\\) weighted standard error) of the barcodes per cluster from the indicated source environment along the \\(x\\) axis, versus, for each ploidy separately: the weighted mean ( \\(\\pm\\) weighted standard error) of fitness change in the away environments along the \\(y\\) -axis (top panel) the weighted standard deviation in fitness change in the away environments along the \\(y\\) -axis (lower panel). 1N plots, by cluster Haploid \\(s_{\\text{home}}\\) versus \\(\\mu(s_{\\text{away}})\\) Haploid \\(s_{\\text{home}}\\) versus \\(\\sigma(s_{\\text{away}})\\) 2N plots, by cluster Diploid \\(s_{\\text{home}}\\) versus \\(\\mu(s_{\\text{away}})\\) Diploid \\(s_{\\text{home}}\\) versus \\(\\mu(s_{\\text{away}})\\)","title":"Home v away comparisons"},{"location":"Results/Fitness%20patterns/scatterplots.html#home-v-away-comparisons","text":"Plots below represent the weighted mean fitness in the home environment ( \\(\\pm\\) weighted standard error) of the barcodes per cluster from the indicated source environment along the \\(x\\) axis, versus, for each ploidy separately: the weighted mean ( \\(\\pm\\) weighted standard error) of fitness change in the away environments along the \\(y\\) -axis (top panel) the weighted standard deviation in fitness change in the away environments along the \\(y\\) -axis (lower panel).","title":"Home v away comparisons"},{"location":"Results/Fitness%20patterns/scatterplots.html#1n-plots-by-cluster","text":"Haploid \\(s_{\\text{home}}\\) versus \\(\\mu(s_{\\text{away}})\\) Haploid \\(s_{\\text{home}}\\) versus \\(\\sigma(s_{\\text{away}})\\)","title":"1N plots, by cluster"},{"location":"Results/Fitness%20patterns/scatterplots.html#2n-plots-by-cluster","text":"Diploid \\(s_{\\text{home}}\\) versus \\(\\mu(s_{\\text{away}})\\) Diploid \\(s_{\\text{home}}\\) versus \\(\\mu(s_{\\text{away}})\\)","title":"2N plots, by cluster"},{"location":"Results/Lineage%20summaries/summaries.html","text":"Summary of adapted lineages by ploidy Plots 1N lineage summary 2N lineage summary Tables 1N lineage summary source n_bcs n_bcs_adapted p_bcs_adapted n_wgs p_wgs n_bcs_adapted_wgs p_adapted_w_wgs n_clusters GlyEtOH 124 70 0.56 47 0.38 31 0.44 14 CLM 67 63 0.94 39 0.58 36 0.57 7 pH7_3 143 62 0.43 0 0 0 0 2 FLC4 82 61 0.74 32 0.39 25 0.41 15 SC 261 6 0.02 0 0 0 0 6 YPD 232 5 0.02 1 0 0 0 3 21C 301 2 0.01 1 0 0 0 3 37C 119 0 0 0 0 0 NaN 1 pH3_8 128 0 0 1 0.01 0 NaN 1 2N lineage summary source n_bcs n_bcs_adapted p_bcs_adapted n_wgs p_wgs n_bcs_adapted_wgs p_adapted_w_wgs n_clusters FLC4 569 552 0.97 118 0.21 116 0.21 8 21C 331 139 0.42 18 0.05 16 0.12 10 GlyEtOH 162 110 0.68 18 0.11 15 0.14 14 CLM 95 82 0.86 29 0.31 25 0.3 3 02M_NaCl 426 67 0.16 16 0.04 8 0.12 7 37C 325 27 0.08 14 0.04 4 0.15 9 pH3_8 378 25 0.07 0 0 0 0 6 pH7_3 343 24 0.07 6 0.02 4 0.17 4 YPD 279 15 0.05 0 0 0 0 4 48Hr 123 13 0.11 0 0 0 0 7 SC 289 1 0 1 0 0 0 2 Ancestor_YPD 90 0 0 1 0.01 0 NaN 1","title":"Summary of adapted lineages by ploidy"},{"location":"Results/Lineage%20summaries/summaries.html#summary-of-adapted-lineages-by-ploidy","text":"","title":"Summary of adapted lineages by ploidy"},{"location":"Results/Lineage%20summaries/summaries.html#plots","text":"","title":"Plots"},{"location":"Results/Lineage%20summaries/summaries.html#1n-lineage-summary","text":"","title":"1N lineage summary"},{"location":"Results/Lineage%20summaries/summaries.html#2n-lineage-summary","text":"","title":"2N lineage summary"},{"location":"Results/Lineage%20summaries/summaries.html#tables","text":"","title":"Tables"},{"location":"Results/Lineage%20summaries/summaries.html#1n-lineage-summary_1","text":"source n_bcs n_bcs_adapted p_bcs_adapted n_wgs p_wgs n_bcs_adapted_wgs p_adapted_w_wgs n_clusters GlyEtOH 124 70 0.56 47 0.38 31 0.44 14 CLM 67 63 0.94 39 0.58 36 0.57 7 pH7_3 143 62 0.43 0 0 0 0 2 FLC4 82 61 0.74 32 0.39 25 0.41 15 SC 261 6 0.02 0 0 0 0 6 YPD 232 5 0.02 1 0 0 0 3 21C 301 2 0.01 1 0 0 0 3 37C 119 0 0 0 0 0 NaN 1 pH3_8 128 0 0 1 0.01 0 NaN 1","title":"1N lineage summary"},{"location":"Results/Lineage%20summaries/summaries.html#2n-lineage-summary_1","text":"source n_bcs n_bcs_adapted p_bcs_adapted n_wgs p_wgs n_bcs_adapted_wgs p_adapted_w_wgs n_clusters FLC4 569 552 0.97 118 0.21 116 0.21 8 21C 331 139 0.42 18 0.05 16 0.12 10 GlyEtOH 162 110 0.68 18 0.11 15 0.14 14 CLM 95 82 0.86 29 0.31 25 0.3 3 02M_NaCl 426 67 0.16 16 0.04 8 0.12 7 37C 325 27 0.08 14 0.04 4 0.15 9 pH3_8 378 25 0.07 0 0 0 0 6 pH7_3 343 24 0.07 6 0.02 4 0.17 4 YPD 279 15 0.05 0 0 0 0 4 48Hr 123 13 0.11 0 0 0 0 7 SC 289 1 0 1 0 0 0 2 Ancestor_YPD 90 0 0 1 0.01 0 NaN 1","title":"2N lineage summary"},{"location":"Supplemental%20Information/si_methods.html","text":"Supplemental Methods Double barcode design Overview The DNA barcoding system developed in Levy et al. [-@Levy15a] allows for the use of two distinct DNA barcodes \u2013 one in the landing pad itself, introduced via homologous recombination, and a second, which is introduced via Cre-lox mediated recombination. In Levy et al. [-@Levy15a], only a single sequence was used for the landing pad barcode, but here we used the landing pad barcode as a low complexity barcode to encode the experimental condition under which a population was evolved, while we used the other barcode (as in Levy et al. [-@Levy15a]) for lineage tracking itself. Figure S1 details the stepwise approach by which the barcoded populations were generated. Ancestral strain construction To generate the ancestral strain for barcoding, we first constructed strain HR206, which contains the Magic Marker (Tong et al. 2004) by XXX . HR206 was then crossed strain SHA321 [@Jaffe17a], which carries the pre-landing pad, Gal-Cre-NatMX , at the YBR209W locus [@Levy15a]. \\(\\text{Mat}\\alpha\\) spores derived from this cross were grown on Nourseothricin (Nat), to select for the pre-landing pad locus, and then one of these was backcrossed to FY3 (Winston et al., 1995). This process was repeated 5 times, each time selecting for \\(\\text{Mat}\\alpha\\) spores containing the landing pad. A single spore derived from the final backcross was used as the ancestor for generating haploid barcoded libraries; one more mating with FY3 was performed to obtain the diploid ancestor. We next introduced the barcoded landing pad into the pre-landing pad locus by homologous recombination with NatMX (Figure S1). The landing pad contains a lox66 site, a DNA barcode (which we refer to as BC1), an artificial intron, the 3\u2019 half of URA3 , and HygMX . We PCR amplified the fragment of interest from the plasmid library L001 (~75,000 barcodes), described in Jaffe et al. [-@Jaffe17a] and transformed to obtain a library of landing pad strains containing a BC1 barcode. The transformation protocol is as described in detail in Levy et al [-@Levy15a]. Construction of high diversity libraries We selected 101 barcoded landing pad haploid strains and 117 barcoded landing pad diploid strains, listed in Table S2 with their associated environment for evolution. Each individual barcoded landing pad was then transformed using the plasmid library pBAR3-L1 (~500,000 barcodes) described in Levy et al. [-@Levy15a]. This plasmid carries lox71 , a DNA barcode (referred to as BC2), an artificial intron, the 5\u2019 half of URA3 , and HygMX . Transformants were selected onto SC +Gal \u2013Ura, to allow expression of the Cre recombinase, which is under the GAL1 promoter. The recombination between lox66 and lox71 is irreversible and brings the two barcodes in close proximity to form an intron within the complete and functional URA3 gene. For each landing pad strain, we generated \\(10^{4}-10^{5}\\) transformants. The plates were scraped, and transformants from each plate were stored separately in glycerol at -80\u00b0C. To estimate barcode diversity in each of the single libraries, we performed high throughput sequencing of the barcode region following DNA extraction (described in detail below). Using this sequence data, we quantified the distribution of frequencies of all unique barcodes present in each single library. We then pooled non-overlapping sets of these single libraries in order to obtain 12 pools (per ploidy) estimated to contain ~500,000 unique lineages (combination of BC1 and BC2). The number of landing pad (BC1) strains per pool ranged from 4 to 16. The minimum Hamming distance between landing pad barcodes within any pool is 6 for the diploid pools and 7 for the haploid pools. Table S1. Primers and details on DBC construction, primers, etc. WIP Table S2. with statistics on library size, diversity, from ancestral pools. WIP Experimental evolution protocols Growth conditions and transfer regime Each starting pool was evolved by serial batch culture in 500 mL baffled flasks in various conditions described below (Table S3). Unless otherwise specified, vegetative propagation was conducted in in 100 mL of each media at 30\u00b0C with shaking at 225 rpm. Base medium for most conditions was SC complete (YNB+ Nitrogen- 1501-500, SC-1300-500, Sunrise Science Products) supplemented with 2% Glucose (BD-Difco-215510). The evolution experiments were started with a pre-culture of each pool grown in 100 mL of SC-2% Glucose at 30\u00b0C overnight. This pre-culture was used to inoculate both replicate evolutions with \\(\\sim 10^7\\) cells (~400 \u00b5L). Table S3. Media recipe per source environment. WIP Serial transfers were performed by transferring \\(\\sim 10^7\\) cells (~ 400 \u00b5L) into fresh media at the designated transfer time (24 hours for most environments; Table S3). We generated archival glycerol stocks (3 \\(\\times\\) 1 mL culture at 16.6% final glycerol concentration), and pelleted, washed, and concentrated the remaining culture volume (90 mL) for later DNA extraction and barcode sequencing (described below). Bulk Fitness Assay Assembling clone pools We generated pools of adapted genotypes by isolating individual yeast clones from each of our evolution environments. To do so, we first determined appropriate time point(s) from which to sample in order to gather a large number of unique lineages carrying distinct beneficial mutations. When isolating lineages from time points throughout the evolutions, we were faced with trying to balance requiring that clones be adapted with the necessity of sampling as many unique adapted lineages at once. We first measured population mean fitness using bulk population fitness assays against a fluorescently labeled reference strain (describe below) to determine time points with high mean fitness. For many environments, sampling clones from time-point(s) shortly after mean fitness began to consistently increase yielded sufficiently high numbers of lineages that were adapted and had unique barcodes. However, several evolution environments showing positive mean fitness were dominated by a very small number of lineages, such that few unique barcodes were recovered after clone isolation. To solve this problem, we took advantage of low-coverage barcode sequencing of various time points from the initial evolutions. Using a simple heuristic to define whether barcodes were adapted, we calculated the time point which would yield the largest number of unique and adapted barcodes in a sample of \\(N\\) clones per time point. To isolate clones from the selected time points, we inoculated a ~10 \u00b5L aliquot of frozen glycerol stocks of the target sample into 5 mL of YPD and grew this pre-culture overnight. This culture was suspended at \\(10^{5}\\) cells per mL in PBS before clone isolation into 96-well plates by way of single cell sorting. Bulk competition protocols WIP: Parris High-throughput barcode sequencing DNA extraction From a dry cell pellet stored at -20\u00b0, DNA was extracted using the MasterPure\u2122 Yeast DNA Purification Kit (Epicentre MPY80200) with slight modifications compared to the manufacturer\u2019s guidelines: the lysis step was performed for one hour in lysis buffer, supplemented with RNAse at 1.66 \u00b5g/\u00b5L. Prior to resuspension with sterile water, each DNA pellet was washed twice with 70% Ethanol to remove remaining contaminants. Following quantification via QuBit\u2122, DNA was resuspended to a final concentration of 50 ng/\u00b5L. PCR Amplification Amplification of the barcode region was performed as previously described [@Levy15a; @Venkataram16a], with the following amendments. Table S4 . Primers used for library construction WIP Table S5. Time points and replicates used for fitness inference from all BFA assays. WIP Fitness inference Demultiplexing Illumina reads and counting barcodes We first divide reads into individual libraries based on inline indices following the unique molecular index on the paired-end reads. We discard reads if the average quality score of the barcode regions is less than 30. The unique molecular index (UMI) for a set of paired reads is the first 8 bases of read 1 plus the first 8 bases of read 2. For each library, we discard reads with duplicate UMIs. Finally, we extract barcodes by searching the barcode region, plus 10 bases on either side, using the regular expression below. We discard reads that do not match this regular expression ('\\D*?(GTACC|GGACC|GGTCC|G.TACC|GG.ACC|GGT.CC|GGTA.C|GGTAC.)(\\D{24,28})(.TAACT|A.AACT|AT.ACT|ATA.CT|ATAA.T|ATAAC|AAACT|ATACT|ATAAT)\\D*') Clustering / error correcting Because of PCR and sequencing errors, many of the barcodes counted in the previous step are simply errors and should not be counted as \u201ctrue\u201d barcodes. To error correct the set of barcodes for each experiment, we cluster errors to true barcodes based on the edit distance between barcodes. We use the following algorithm to cluster the environment barcodes and diverse barcodes separately. The algorithm takes advantage of the fact that all errors should be connected by single insertions, deletions, and substitutions by using deletion neighborhoods to speed up the error-correction process. The algorithm uses as input a list of barcodes and total counts (reads) corresponding to each barcode. The steps are listed below: Make deletion neighborhoods For each barcode, create the set of single-base deletions at each position Connect barcodes with overlapping single-base deletion sets Note: this overlap indicates that the two barcodes are separated by one \u201cedit\u201d: a substitution, insertion, or deletion Within each neighborhood, define peaks by these criteria: Barcode does not contain an uncalled base (\u201cN\u201d) Barcode has no single-edit neighbors with more total counts Barcode has more than 10 total counts Barcode is more than 3 edits away from any peak with more total counts Within each neighborhood, error correct non-peak barcodes: Check the Levenshtein (edit) distance between each non-peak barcode and each peak barcode. If the edit distance is less than or equal to 3, the barcode error-corrects to the peak barcode. If a barcode is within 3 edits of more than one peak, it corrects to the barcode with higher total counts Note: This step uses the python Levenshtein module (https://pypi.python.org/pypi/python-Levenshtein/0.12.0#license) Once we have error-corrected both the environment and diverse barcodes, we define the combinations of \u201ctrue\u201d environment and diverse barcodes, which we call \u201ccentroids.\u201d We discard combinations that have less than or equal to 10 total counts and add the counts from error barcodes to the appropriate centroids to produce a final list of barcodes and counts. Final steps Because the bulk fitness assays were all sequenced over multiple lanes, we perform the above steps for each lane separately and then combine count files based on full barcode (environment barcode + diverse barcode) sequences. We discard any full barcodes that are not found in all lanes, which removes any lane-specific sequencing contamination. Chimeric barcode pairs, which arise from sequencing or PCR issues, occur at a low rate in our reads. We identify chimeras by finding barcodes that share a diverse barcode (but not an environment barcode) with another barcode that has at least 100X more reads. These barcodes are removed from the dataset. Whole-genome clone sequencing Clone selection WIP: Parris/Milo Table S7. Adapted clones per environment inferred from BFAs, with number with WGS sequencing data. WIP Library preparation WIP: Lucas/Parris Variant calling pipeline Table S8. Number of mutations discovered per clone per source and ploidy. WIP The pipeline for variants calling has been detailed in Li, et al., 2019 (Nature Eco&Evo). Briefly, Sentieon Genomic Tools Version 201711.02 (REF: doi:10.1101/115717 ) were used for SNP, small indel and structural variants calling with S. cerevisiae S288C reference genome R64-1-1 (https://downloads.yeastgenome.org/sequence/S288C_reference/genome_releases/). The source code for variants calling and annotation (section 7.2-7.6) can be found at https://github.com/liyuping927/DNAscope-variants-calling. FASTQ processing For each sample, we received two .fastq files, one for each read of the paired end sequencing ('fastqR1' and 'fastqR2'). Using cutadapt v.1.16 , we trimmed the first 10 bp of each read ( -u 10 ), low-quality ends ( -q 30 ) and any adapter sequences ( -a ). After trimming, sequences with a length shorter than 12 bp ( --minimum-length 12 ) were discarded. First we trimmed the forward read, writing output to temporary files (note, commands are a single line): cutadapt --minimum-length 12 -q 30 -u 10 -a CTGTCTCTTATACACATCTCCGAGCCCACGAGAC -o tmp.1.fastq.gz -p tmp.2.fastq.gz fastqR1 fastqR2 Next we trimmed the reverse read, using the temporary files as input: cutadapt --minimum-length 12 -q 30 -u 10 -a CTGTCTCTTATACACATCTGACGCTGCCGACGA -o trimmedR2.fastq.gz -p trimmedR1.fastq.gz tmp.2.fastq.gz tmp.1.fastq.gz We then mapped reads using bwa (citation) to S. cerevisiae S288C reference genome R64-1-1 ( https://downloads.yeastgenome.org/sequence/S288C_reference/genome_releases/ ) and sorted using Sentieon Genomic Tools v.6 : bwa mem -M -R readGroupInfo -K 10000000 ReferenceGenome trimmedR1.fastq.gz trimmedR2.fastq.gz) | sentieon util sort -o SORTED_BAM --sam2bam -i Duplicates were removed using the sorted . bam file. The first command collected read information, and the second command performed the de-duping: sentieon driver -i SORTED_BAM --algo LocusCollector --fun score_info SCORE_TXT sentieon driver -i SORTED_BAM --algo Dedup -- rmdup --score_info SCORE_TXT --metrics DEDUP_METRIC_TXT DEDUP_BAM Local realignment around indels was performed using the deduped .bam file: sentieon driver -r ReferenceGenome -i DEDUP_BAM -- algo Realigner REALIGNED_BAM Lastly, base quality score re-calibration was performed using the realigned .bam file. The first command calculated the required modification of the quality scores assigned to individual read bases of the sequence read data. The second command applied the re-calibration to calculate the post calibration data table: sentieon driver -r ReferenceGenome -i REALIGNED_BAM --algo QualCal RECAL_DATA.TABLE sentieon driver -r ReferenceGenome -i REALIGNED_BAM -q RECAL_DATA.TABLE --algo QualCal RECAL_DATA.TABLE.POST SNP and small indel variant calling SNP and small indels variants were called by the DNAscope algorithm (Sentieon Genomic Software) using the realigned .bam file and the output table of the base quality score recalibration ( RECAL_DATA.TABLE ). The parameter ploidy is assigned as 1 for haploids and as 2 for diploids. sentieon driver -r ReferenceGenome -i REALIGNED_BAM -q RECAL_DATA.TABLE --algo DNAscope --ploidy [1|2] VARIANT_VCF Structural variant calling The first command enabled the DNAscope algorithm to detect the break-end variant type (BND). The parameter ploidy was assigned as 1 for haploids and as 2 for diploids. The second command processed the temporary .vcf file using the SVSolver algorithm and output structural variants to a .vcf file. sentieon driver -r ReferenceGenome -i REALIGNED_BAM -q RECAL_DATA.TABLE --algo DNAscope --var_type bnd --ploidy [1|2] TMP_VARIANT_VCF Then process the .vcf using the SVSolver algorithm with the following command: sentieon driver -r ReferenceGenome --algo SVSolver -v TMP_VARIANT_VCF STRUCTURAL_VARIANT_VCF Variant annotation Here the .vcf file from SNP and small indel variants calling ( VARIANT_VCF ) is used as an example. The same commands were used to annotate structural variants. We then used snpEff7 ( http://snpeff.sourceforge.net/download.html ) to annotate a .vcf file and output the annotated .vcf file, named Ann.vcf . java -Xmx2g -jar snpEff -c snpEff_config -v R64-1-1.75 -class VARIANT_VCF > Ann.vcf -s snpEff_summary.html For variants in coding regions, SNPSift was used to extract the first annotation of each variant, which is the annotation with the largest effect. Output the extracted annotation as a .vcf file, named Final_Ann.vcf : java -jar SnpSift extractFields Ann.vcf CHROM POS ID REF ALT QUAL FILTER EFF[0].EFFECT EFF[0].GENE: EFF[0].IMPACT: EFF[0].FUNCLASS: EFF[0].CODON: EFF[0].AA ANN[0].BIOTYPE: GEN[0].GT GEN[0].AD GEN[0].DP GEN[0].GQ GEN[0].PL > Final_Ann.vcf For variants in non-coding regions, the nearest gene of each variant was extracted. Thus, the non-coding variants were annotated as either the upstream or downstream of the nearest genes. Filtering SNPs, small indels, and structural variants First, mitochondrial variants were discarded. Second, any variants in genes FLO1 and FLO9 were filtered out due to poor alignment in both genomic regions. Third, diploids with an average coverage lower than 15 and haploids with an average coverage lower than 10 were discarded. Fourth, background variants were removed. If a variant is present in >~12% of clones isolated from the same evolutionary condition, this variant is considered as a background variant and discarded. Fifth, variants with a quality score smaller than 150 were filtered out. Note that if a variant was present in multiple clones, the alignment of this variant was manually checked regardless of its quality score and a decision was made based on all clones carrying this variant. Thus, a variant with a quality score <150 may not be filtered out if the same variant contained in other clones was proven to be authentic. Similarly, a variant with a quality score >150 may be filtered out if the same variant was proven to be bogus in other clones. Furthermore, all variants were further verified by manually checking .bam files after alignment. By doing this, variants within repetitive regions and regions with a poor alignment were filtered out. More importantly, due to mishandling, sequencing data used here is contaminated by other yeast species/isolates at a low frequency (0-30%). While this low frequency contamination does not pose a big problem for variants calling in haploids, it leads to excessive miscalling of heterozygous variants in diploids. These miscalled heterozygous variants are caused by genetic variations between S288C (the S. cerevisiae strain used in this study) and the contaminated yeast source and often appear in \u201cpatch\u201d (multiple variants within a small region, e.g. 4 variants within 100 bp), which is statistically impossible considering the short-period evolutionary time. To remove false variants caused by contamination, we manually checked alignment through .bam files and removed heterozygous variants appearing in patch. In addition, the ratio of ref:alt is used to assist the removal of false variants. Variants with Ref:Alt >3:1 are very likely to be a result of low-frequency contamination. Lastly, ambiguous variants were checked using blast. Variants that are not present in other yeast species/isolates were considered as de novo mutations arising during the course of evolution. Identifying large rearrangements and aneuploidies WIP: Lucas Statistical analyses of fitness and pleiotropy WIP Parris Statistical analysis of fitness patterns Identifying adapted lineages Identifying auto-diploidized lineages Clustering and variance partitioning Table S8. Number of lineages in each of \\(k\\) clusters defines for each source environment, as well as robustness statistics to groupings. WIP Linking phenotypes with genotypes Mutual information Hierarchical gene--pathway analysis References","title":"Supplemental Methods"},{"location":"Supplemental%20Information/si_methods.html#supplemental-methods","text":"","title":"Supplemental Methods"},{"location":"Supplemental%20Information/si_methods.html#double-barcode-design","text":"","title":"Double barcode design"},{"location":"Supplemental%20Information/si_methods.html#overview","text":"The DNA barcoding system developed in Levy et al. [-@Levy15a] allows for the use of two distinct DNA barcodes \u2013 one in the landing pad itself, introduced via homologous recombination, and a second, which is introduced via Cre-lox mediated recombination. In Levy et al. [-@Levy15a], only a single sequence was used for the landing pad barcode, but here we used the landing pad barcode as a low complexity barcode to encode the experimental condition under which a population was evolved, while we used the other barcode (as in Levy et al. [-@Levy15a]) for lineage tracking itself. Figure S1 details the stepwise approach by which the barcoded populations were generated.","title":"Overview"},{"location":"Supplemental%20Information/si_methods.html#ancestral-strain-construction","text":"To generate the ancestral strain for barcoding, we first constructed strain HR206, which contains the Magic Marker (Tong et al. 2004) by XXX . HR206 was then crossed strain SHA321 [@Jaffe17a], which carries the pre-landing pad, Gal-Cre-NatMX , at the YBR209W locus [@Levy15a]. \\(\\text{Mat}\\alpha\\) spores derived from this cross were grown on Nourseothricin (Nat), to select for the pre-landing pad locus, and then one of these was backcrossed to FY3 (Winston et al., 1995). This process was repeated 5 times, each time selecting for \\(\\text{Mat}\\alpha\\) spores containing the landing pad. A single spore derived from the final backcross was used as the ancestor for generating haploid barcoded libraries; one more mating with FY3 was performed to obtain the diploid ancestor. We next introduced the barcoded landing pad into the pre-landing pad locus by homologous recombination with NatMX (Figure S1). The landing pad contains a lox66 site, a DNA barcode (which we refer to as BC1), an artificial intron, the 3\u2019 half of URA3 , and HygMX . We PCR amplified the fragment of interest from the plasmid library L001 (~75,000 barcodes), described in Jaffe et al. [-@Jaffe17a] and transformed to obtain a library of landing pad strains containing a BC1 barcode. The transformation protocol is as described in detail in Levy et al [-@Levy15a].","title":"Ancestral strain construction"},{"location":"Supplemental%20Information/si_methods.html#construction-of-high-diversity-libraries","text":"We selected 101 barcoded landing pad haploid strains and 117 barcoded landing pad diploid strains, listed in Table S2 with their associated environment for evolution. Each individual barcoded landing pad was then transformed using the plasmid library pBAR3-L1 (~500,000 barcodes) described in Levy et al. [-@Levy15a]. This plasmid carries lox71 , a DNA barcode (referred to as BC2), an artificial intron, the 5\u2019 half of URA3 , and HygMX . Transformants were selected onto SC +Gal \u2013Ura, to allow expression of the Cre recombinase, which is under the GAL1 promoter. The recombination between lox66 and lox71 is irreversible and brings the two barcodes in close proximity to form an intron within the complete and functional URA3 gene. For each landing pad strain, we generated \\(10^{4}-10^{5}\\) transformants. The plates were scraped, and transformants from each plate were stored separately in glycerol at -80\u00b0C. To estimate barcode diversity in each of the single libraries, we performed high throughput sequencing of the barcode region following DNA extraction (described in detail below). Using this sequence data, we quantified the distribution of frequencies of all unique barcodes present in each single library. We then pooled non-overlapping sets of these single libraries in order to obtain 12 pools (per ploidy) estimated to contain ~500,000 unique lineages (combination of BC1 and BC2). The number of landing pad (BC1) strains per pool ranged from 4 to 16. The minimum Hamming distance between landing pad barcodes within any pool is 6 for the diploid pools and 7 for the haploid pools. Table S1. Primers and details on DBC construction, primers, etc. WIP Table S2. with statistics on library size, diversity, from ancestral pools. WIP","title":"Construction of high diversity libraries"},{"location":"Supplemental%20Information/si_methods.html#experimental-evolution-protocols","text":"","title":"Experimental evolution protocols"},{"location":"Supplemental%20Information/si_methods.html#growth-conditions-and-transfer-regime","text":"Each starting pool was evolved by serial batch culture in 500 mL baffled flasks in various conditions described below (Table S3). Unless otherwise specified, vegetative propagation was conducted in in 100 mL of each media at 30\u00b0C with shaking at 225 rpm. Base medium for most conditions was SC complete (YNB+ Nitrogen- 1501-500, SC-1300-500, Sunrise Science Products) supplemented with 2% Glucose (BD-Difco-215510). The evolution experiments were started with a pre-culture of each pool grown in 100 mL of SC-2% Glucose at 30\u00b0C overnight. This pre-culture was used to inoculate both replicate evolutions with \\(\\sim 10^7\\) cells (~400 \u00b5L). Table S3. Media recipe per source environment. WIP Serial transfers were performed by transferring \\(\\sim 10^7\\) cells (~ 400 \u00b5L) into fresh media at the designated transfer time (24 hours for most environments; Table S3). We generated archival glycerol stocks (3 \\(\\times\\) 1 mL culture at 16.6% final glycerol concentration), and pelleted, washed, and concentrated the remaining culture volume (90 mL) for later DNA extraction and barcode sequencing (described below).","title":"Growth conditions and transfer regime"},{"location":"Supplemental%20Information/si_methods.html#bulk-fitness-assay","text":"","title":"Bulk Fitness Assay"},{"location":"Supplemental%20Information/si_methods.html#assembling-clone-pools","text":"We generated pools of adapted genotypes by isolating individual yeast clones from each of our evolution environments. To do so, we first determined appropriate time point(s) from which to sample in order to gather a large number of unique lineages carrying distinct beneficial mutations. When isolating lineages from time points throughout the evolutions, we were faced with trying to balance requiring that clones be adapted with the necessity of sampling as many unique adapted lineages at once. We first measured population mean fitness using bulk population fitness assays against a fluorescently labeled reference strain (describe below) to determine time points with high mean fitness. For many environments, sampling clones from time-point(s) shortly after mean fitness began to consistently increase yielded sufficiently high numbers of lineages that were adapted and had unique barcodes. However, several evolution environments showing positive mean fitness were dominated by a very small number of lineages, such that few unique barcodes were recovered after clone isolation. To solve this problem, we took advantage of low-coverage barcode sequencing of various time points from the initial evolutions. Using a simple heuristic to define whether barcodes were adapted, we calculated the time point which would yield the largest number of unique and adapted barcodes in a sample of \\(N\\) clones per time point. To isolate clones from the selected time points, we inoculated a ~10 \u00b5L aliquot of frozen glycerol stocks of the target sample into 5 mL of YPD and grew this pre-culture overnight. This culture was suspended at \\(10^{5}\\) cells per mL in PBS before clone isolation into 96-well plates by way of single cell sorting.","title":"Assembling clone pools"},{"location":"Supplemental%20Information/si_methods.html#bulk-competition-protocols","text":"WIP: Parris","title":"Bulk competition protocols"},{"location":"Supplemental%20Information/si_methods.html#high-throughput-barcode-sequencing","text":"","title":"High-throughput barcode sequencing"},{"location":"Supplemental%20Information/si_methods.html#dna-extraction","text":"From a dry cell pellet stored at -20\u00b0, DNA was extracted using the MasterPure\u2122 Yeast DNA Purification Kit (Epicentre MPY80200) with slight modifications compared to the manufacturer\u2019s guidelines: the lysis step was performed for one hour in lysis buffer, supplemented with RNAse at 1.66 \u00b5g/\u00b5L. Prior to resuspension with sterile water, each DNA pellet was washed twice with 70% Ethanol to remove remaining contaminants. Following quantification via QuBit\u2122, DNA was resuspended to a final concentration of 50 ng/\u00b5L.","title":"DNA extraction"},{"location":"Supplemental%20Information/si_methods.html#pcr-amplification","text":"Amplification of the barcode region was performed as previously described [@Levy15a; @Venkataram16a], with the following amendments. Table S4 . Primers used for library construction WIP Table S5. Time points and replicates used for fitness inference from all BFA assays. WIP","title":"PCR Amplification"},{"location":"Supplemental%20Information/si_methods.html#fitness-inference","text":"","title":"Fitness inference"},{"location":"Supplemental%20Information/si_methods.html#demultiplexing-illumina-reads-and-counting-barcodes","text":"We first divide reads into individual libraries based on inline indices following the unique molecular index on the paired-end reads. We discard reads if the average quality score of the barcode regions is less than 30. The unique molecular index (UMI) for a set of paired reads is the first 8 bases of read 1 plus the first 8 bases of read 2. For each library, we discard reads with duplicate UMIs. Finally, we extract barcodes by searching the barcode region, plus 10 bases on either side, using the regular expression below. We discard reads that do not match this regular expression ('\\D*?(GTACC|GGACC|GGTCC|G.TACC|GG.ACC|GGT.CC|GGTA.C|GGTAC.)(\\D{24,28})(.TAACT|A.AACT|AT.ACT|ATA.CT|ATAA.T|ATAAC|AAACT|ATACT|ATAAT)\\D*')","title":"Demultiplexing Illumina reads and counting barcodes"},{"location":"Supplemental%20Information/si_methods.html#clustering-error-correcting","text":"Because of PCR and sequencing errors, many of the barcodes counted in the previous step are simply errors and should not be counted as \u201ctrue\u201d barcodes. To error correct the set of barcodes for each experiment, we cluster errors to true barcodes based on the edit distance between barcodes. We use the following algorithm to cluster the environment barcodes and diverse barcodes separately. The algorithm takes advantage of the fact that all errors should be connected by single insertions, deletions, and substitutions by using deletion neighborhoods to speed up the error-correction process. The algorithm uses as input a list of barcodes and total counts (reads) corresponding to each barcode. The steps are listed below: Make deletion neighborhoods For each barcode, create the set of single-base deletions at each position Connect barcodes with overlapping single-base deletion sets Note: this overlap indicates that the two barcodes are separated by one \u201cedit\u201d: a substitution, insertion, or deletion Within each neighborhood, define peaks by these criteria: Barcode does not contain an uncalled base (\u201cN\u201d) Barcode has no single-edit neighbors with more total counts Barcode has more than 10 total counts Barcode is more than 3 edits away from any peak with more total counts Within each neighborhood, error correct non-peak barcodes: Check the Levenshtein (edit) distance between each non-peak barcode and each peak barcode. If the edit distance is less than or equal to 3, the barcode error-corrects to the peak barcode. If a barcode is within 3 edits of more than one peak, it corrects to the barcode with higher total counts Note: This step uses the python Levenshtein module (https://pypi.python.org/pypi/python-Levenshtein/0.12.0#license) Once we have error-corrected both the environment and diverse barcodes, we define the combinations of \u201ctrue\u201d environment and diverse barcodes, which we call \u201ccentroids.\u201d We discard combinations that have less than or equal to 10 total counts and add the counts from error barcodes to the appropriate centroids to produce a final list of barcodes and counts.","title":"Clustering / error correcting"},{"location":"Supplemental%20Information/si_methods.html#final-steps","text":"Because the bulk fitness assays were all sequenced over multiple lanes, we perform the above steps for each lane separately and then combine count files based on full barcode (environment barcode + diverse barcode) sequences. We discard any full barcodes that are not found in all lanes, which removes any lane-specific sequencing contamination. Chimeric barcode pairs, which arise from sequencing or PCR issues, occur at a low rate in our reads. We identify chimeras by finding barcodes that share a diverse barcode (but not an environment barcode) with another barcode that has at least 100X more reads. These barcodes are removed from the dataset.","title":"Final steps"},{"location":"Supplemental%20Information/si_methods.html#whole-genome-clone-sequencing","text":"","title":"Whole-genome clone sequencing"},{"location":"Supplemental%20Information/si_methods.html#clone-selection","text":"WIP: Parris/Milo Table S7. Adapted clones per environment inferred from BFAs, with number with WGS sequencing data. WIP","title":"Clone selection"},{"location":"Supplemental%20Information/si_methods.html#library-preparation","text":"WIP: Lucas/Parris","title":"Library preparation"},{"location":"Supplemental%20Information/si_methods.html#variant-calling-pipeline","text":"Table S8. Number of mutations discovered per clone per source and ploidy. WIP The pipeline for variants calling has been detailed in Li, et al., 2019 (Nature Eco&Evo). Briefly, Sentieon Genomic Tools Version 201711.02 (REF: doi:10.1101/115717 ) were used for SNP, small indel and structural variants calling with S. cerevisiae S288C reference genome R64-1-1 (https://downloads.yeastgenome.org/sequence/S288C_reference/genome_releases/). The source code for variants calling and annotation (section 7.2-7.6) can be found at https://github.com/liyuping927/DNAscope-variants-calling.","title":"Variant calling pipeline"},{"location":"Supplemental%20Information/si_methods.html#fastq-processing","text":"For each sample, we received two .fastq files, one for each read of the paired end sequencing ('fastqR1' and 'fastqR2'). Using cutadapt v.1.16 , we trimmed the first 10 bp of each read ( -u 10 ), low-quality ends ( -q 30 ) and any adapter sequences ( -a ). After trimming, sequences with a length shorter than 12 bp ( --minimum-length 12 ) were discarded. First we trimmed the forward read, writing output to temporary files (note, commands are a single line): cutadapt --minimum-length 12 -q 30 -u 10 -a CTGTCTCTTATACACATCTCCGAGCCCACGAGAC -o tmp.1.fastq.gz -p tmp.2.fastq.gz fastqR1 fastqR2 Next we trimmed the reverse read, using the temporary files as input: cutadapt --minimum-length 12 -q 30 -u 10 -a CTGTCTCTTATACACATCTGACGCTGCCGACGA -o trimmedR2.fastq.gz -p trimmedR1.fastq.gz tmp.2.fastq.gz tmp.1.fastq.gz We then mapped reads using bwa (citation) to S. cerevisiae S288C reference genome R64-1-1 ( https://downloads.yeastgenome.org/sequence/S288C_reference/genome_releases/ ) and sorted using Sentieon Genomic Tools v.6 : bwa mem -M -R readGroupInfo -K 10000000 ReferenceGenome trimmedR1.fastq.gz trimmedR2.fastq.gz) | sentieon util sort -o SORTED_BAM --sam2bam -i Duplicates were removed using the sorted . bam file. The first command collected read information, and the second command performed the de-duping: sentieon driver -i SORTED_BAM --algo LocusCollector --fun score_info SCORE_TXT sentieon driver -i SORTED_BAM --algo Dedup -- rmdup --score_info SCORE_TXT --metrics DEDUP_METRIC_TXT DEDUP_BAM Local realignment around indels was performed using the deduped .bam file: sentieon driver -r ReferenceGenome -i DEDUP_BAM -- algo Realigner REALIGNED_BAM Lastly, base quality score re-calibration was performed using the realigned .bam file. The first command calculated the required modification of the quality scores assigned to individual read bases of the sequence read data. The second command applied the re-calibration to calculate the post calibration data table: sentieon driver -r ReferenceGenome -i REALIGNED_BAM --algo QualCal RECAL_DATA.TABLE sentieon driver -r ReferenceGenome -i REALIGNED_BAM -q RECAL_DATA.TABLE --algo QualCal RECAL_DATA.TABLE.POST","title":"FASTQ processing"},{"location":"Supplemental%20Information/si_methods.html#snp-and-small-indel-variant-calling","text":"SNP and small indels variants were called by the DNAscope algorithm (Sentieon Genomic Software) using the realigned .bam file and the output table of the base quality score recalibration ( RECAL_DATA.TABLE ). The parameter ploidy is assigned as 1 for haploids and as 2 for diploids. sentieon driver -r ReferenceGenome -i REALIGNED_BAM -q RECAL_DATA.TABLE --algo DNAscope --ploidy [1|2] VARIANT_VCF","title":"SNP and small indel variant calling"},{"location":"Supplemental%20Information/si_methods.html#structural-variant-calling","text":"The first command enabled the DNAscope algorithm to detect the break-end variant type (BND). The parameter ploidy was assigned as 1 for haploids and as 2 for diploids. The second command processed the temporary .vcf file using the SVSolver algorithm and output structural variants to a .vcf file. sentieon driver -r ReferenceGenome -i REALIGNED_BAM -q RECAL_DATA.TABLE --algo DNAscope --var_type bnd --ploidy [1|2] TMP_VARIANT_VCF Then process the .vcf using the SVSolver algorithm with the following command: sentieon driver -r ReferenceGenome --algo SVSolver -v TMP_VARIANT_VCF STRUCTURAL_VARIANT_VCF","title":"Structural variant calling"},{"location":"Supplemental%20Information/si_methods.html#variant-annotation","text":"Here the .vcf file from SNP and small indel variants calling ( VARIANT_VCF ) is used as an example. The same commands were used to annotate structural variants. We then used snpEff7 ( http://snpeff.sourceforge.net/download.html ) to annotate a .vcf file and output the annotated .vcf file, named Ann.vcf . java -Xmx2g -jar snpEff -c snpEff_config -v R64-1-1.75 -class VARIANT_VCF > Ann.vcf -s snpEff_summary.html For variants in coding regions, SNPSift was used to extract the first annotation of each variant, which is the annotation with the largest effect. Output the extracted annotation as a .vcf file, named Final_Ann.vcf : java -jar SnpSift extractFields Ann.vcf CHROM POS ID REF ALT QUAL FILTER EFF[0].EFFECT EFF[0].GENE: EFF[0].IMPACT: EFF[0].FUNCLASS: EFF[0].CODON: EFF[0].AA ANN[0].BIOTYPE: GEN[0].GT GEN[0].AD GEN[0].DP GEN[0].GQ GEN[0].PL > Final_Ann.vcf For variants in non-coding regions, the nearest gene of each variant was extracted. Thus, the non-coding variants were annotated as either the upstream or downstream of the nearest genes.","title":"Variant annotation"},{"location":"Supplemental%20Information/si_methods.html#filtering-snps-small-indels-and-structural-variants","text":"First, mitochondrial variants were discarded. Second, any variants in genes FLO1 and FLO9 were filtered out due to poor alignment in both genomic regions. Third, diploids with an average coverage lower than 15 and haploids with an average coverage lower than 10 were discarded. Fourth, background variants were removed. If a variant is present in >~12% of clones isolated from the same evolutionary condition, this variant is considered as a background variant and discarded. Fifth, variants with a quality score smaller than 150 were filtered out. Note that if a variant was present in multiple clones, the alignment of this variant was manually checked regardless of its quality score and a decision was made based on all clones carrying this variant. Thus, a variant with a quality score <150 may not be filtered out if the same variant contained in other clones was proven to be authentic. Similarly, a variant with a quality score >150 may be filtered out if the same variant was proven to be bogus in other clones. Furthermore, all variants were further verified by manually checking .bam files after alignment. By doing this, variants within repetitive regions and regions with a poor alignment were filtered out. More importantly, due to mishandling, sequencing data used here is contaminated by other yeast species/isolates at a low frequency (0-30%). While this low frequency contamination does not pose a big problem for variants calling in haploids, it leads to excessive miscalling of heterozygous variants in diploids. These miscalled heterozygous variants are caused by genetic variations between S288C (the S. cerevisiae strain used in this study) and the contaminated yeast source and often appear in \u201cpatch\u201d (multiple variants within a small region, e.g. 4 variants within 100 bp), which is statistically impossible considering the short-period evolutionary time. To remove false variants caused by contamination, we manually checked alignment through .bam files and removed heterozygous variants appearing in patch. In addition, the ratio of ref:alt is used to assist the removal of false variants. Variants with Ref:Alt >3:1 are very likely to be a result of low-frequency contamination. Lastly, ambiguous variants were checked using blast. Variants that are not present in other yeast species/isolates were considered as de novo mutations arising during the course of evolution.","title":"Filtering SNPs, small indels, and structural variants"},{"location":"Supplemental%20Information/si_methods.html#identifying-large-rearrangements-and-aneuploidies","text":"WIP: Lucas","title":"Identifying large rearrangements and aneuploidies"},{"location":"Supplemental%20Information/si_methods.html#statistical-analyses-of-fitness-and-pleiotropy","text":"WIP Parris","title":"Statistical analyses of fitness and pleiotropy"},{"location":"Supplemental%20Information/si_methods.html#statistical-analysis-of-fitness-patterns","text":"","title":"Statistical analysis of fitness patterns"},{"location":"Supplemental%20Information/si_methods.html#identifying-adapted-lineages","text":"","title":"Identifying adapted lineages"},{"location":"Supplemental%20Information/si_methods.html#identifying-auto-diploidized-lineages","text":"","title":"Identifying auto-diploidized lineages"},{"location":"Supplemental%20Information/si_methods.html#clustering-and-variance-partitioning","text":"Table S8. Number of lineages in each of \\(k\\) clusters defines for each source environment, as well as robustness statistics to groupings. WIP","title":"Clustering and variance partitioning"},{"location":"Supplemental%20Information/si_methods.html#linking-phenotypes-with-genotypes","text":"","title":"Linking phenotypes with genotypes"},{"location":"Supplemental%20Information/si_methods.html#mutual-information","text":"","title":"Mutual information"},{"location":"Supplemental%20Information/si_methods.html#hierarchical-gene-pathway-analysis","text":"","title":"Hierarchical gene--pathway analysis"},{"location":"Supplemental%20Information/si_methods.html#references","text":"","title":"References"}]}