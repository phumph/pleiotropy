{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Barcode lookup for WGS choices\"\noutput: html_notebook\n---\n\n```{r}\nlibrary(here)\nlibrary(ggplot2)\n```\n\nThis notebook details how we used Sanger reads of BCs from individual 2N clones to decide on which cloces to perform WGS for the following environments:\n\n1. SC 37C\n2. SC pH7.3\n3. 0.2M NaCl\n4. SC 21C\n\nFirst we load the barcodes extracted form the Sanger reads:\n```{r}\n#set_here(path = \"/Users/phumph/Dropbox/PLT/sequencing_info/dBFA2_BC_checks_for_WGS/parsed_BCs_and_wells_mapped/\")\nplates <- Sys.glob(here(\"data/dBFA2_parsed_BCs_and_wells_mapped/*.csv\"))\n\n# laod fitness file\nfitnesses <- read.csv(here('data/dBFA2_fitnesses_with_adapt_20APR2018.csv'))\n```\n\nRun through each `plates` entry and add adapted column (0, 1, or NA) along with fitness estimate, also parsing well_ID based on Sanger plate ID built into the name. There are two naming conventions, and each requires its own, so perhaps I'll have to do this manually.\n\nDefine functions:\n```{r}\nstr_splitter <- function(x, sp, nm){\n  x2 <- unlist(strsplit(x, sp))[nm]\n}\n\n# well-mapper\n# assumes column-wise numbering\nwell_mapper <- function(x){\n  the_map <- c('A' = 1,\n                  'B' = 2,\n                  'C' = 3,\n                  'D' = 4,\n                  'E' = 5,\n                  'F' = 6,\n                  'G' = 7,\n                  'H' = 0)\n  mod8 <- x %% 8\n  the_row <- names(the_map)[match(mod8,the_map)]\n  the_col <- ceiling(x/8)\n  if(the_col<10){\n    the_col <- paste0('0',the_col)\n  }\n  the_id <- paste0(the_row,the_col)\n  return(the_id)\n}\n```\n\n\n\n```{r}\nfiles <- list()\nfor (file in 1:length(plates)){\n  files[[file]] <- read.csv(plates[file])\n}\n\nsplit_on <- data.frame(t(matrix(c('_',3,'_',6,'_',2,'_',2),nrow= 2)))\nsplit_on$X2 <- as.numeric(as.vector(split_on$X2))\nthe.res <- list()\nfor (f in 1:length(files)){\n  # define new working file\n  the.file <- data.frame(files[f])\n  \n  # initialize Full.BC column\n  the.file$Full.BC <- '0'\n  \n  # rename columns\n  names(the.file) <- c('ID','Diverse.BC','Environment.BC', 'Full.BC')\n  \n  # parse names:\n  the.file$Full.BC <- paste0(the.file$Diverse.BC,the.file$Environment.BC)\n  \n  # merge with fitness file\n  the.file2 <- merge(the.file, fitnesses, by = 'Full.BC', sort = F)\n  #length(unique(the.file2$Full.BC[the.file2$adapted==1]))\n  \n  # now, parse IDs to find wells:\n  # split on indicated character, indexed by 'file':\n  the.file2$id_well <- sapply(paste0(the.file2$ID), str_splitter, sp = paste0(split_on[f,1]), nm = split_on[f,2])\n  the.file2$id_well <- gsub('.ab1','',the.file2$id_well)\n  the.file2$id_well <- gsub('-PLR2','',the.file2$id_well)\n  \n  # now, output this:\n  the.res[[f]] <- dplyr::arrange(the.file2, id_well)\n}\n\n```\n\nNow, generate output for printing:\n\n```{r}\n# pass the right source env. to script:\ntarget_cols <- c('Full.BC','sources','subpool','ID','id_well','adapted')\n#paste0(here(\"data/dBFA2_parsed_BCs_and_wells_mapped/\"),plates[f])\n\noutput_adapteds <- function(x, target_cols = target_cols, fname){\n  df.tmp <- x[,names(x) %in% target_cols]\n  df.tmp <- df.tmp[df.tmp$adapted == 1,]\n  df.tmp2 <- dplyr::group_by(df.tmp, Full.BC) %>% dplyr::summarise(ID=unique(ID)[1], sources = unique(sources)[1], subpool = unique(subpool)[1], n_wells = length(id_well), first_well = unique(id_well)[1]) %>% dplyr::arrange(first_well)\n  #df.tmp3 <- merge(df.tmp, data.frame(df.tmp2), all.x = F, all.y = F, by = 'Full.BC', sort = F)\n  write.csv(df.tmp2, file = fname,quote = F, row.names = F)\n}\n\nfor (f in 1:length(files)){\n  output_adapteds(the.res[[f]], target_cols = target_cols, fname = paste0(gsub('.csv','',plates[f]),'_parsed.csv'))\n}\n```\n",
    "created" : 1524241624376.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2826436925",
    "id" : "76CA8D8C",
    "lastKnownWriteTime" : 1524254582,
    "last_content_update" : 1524254582443,
    "path" : "~/Dropbox/PLT/analysis_PLT/PLT/BC_mapper.Rmd",
    "project_path" : "BC_mapper.Rmd",
    "properties" : {
        "chunk_output_type" : "inline"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}